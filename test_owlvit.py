from PIL import Image, ImageDraw
import torch
import matplotlib.pyplot as plt
from transformers import OwlViTProcessor, OwlViTForObjectDetection

print("â³ Cargando procesador visual y modelo OwlViT...")
# Configuramos el dispositivo (tarjeta grÃ¡fica si estÃ¡, sino procesador normal)
device = "cuda" if torch.cuda.is_available() else "cpu"

processor = OwlViTProcessor.from_pretrained("google/owlvit-base-patch32")
model = OwlViTForObjectDetection.from_pretrained("google/owlvit-base-patch32").to(device)

# âš ï¸ FOTO DE PRUEBA: Pon aquÃ­ la ruta de una foto chula donde se vea bien la ropa
ruta_foto = "../data/images/bundles/B_568aa697563e.jpg" 
imagen_original = Image.open(ruta_foto).convert("RGB")

# Â¿QuÃ© cosas quieres que la IA busque y separe en la imagen?
etiquetas_a_buscar = [["upper clothing", "pants", "skirt", "dress"]]
print(f"ğŸ” Buscando especÃ­ficamente: {etiquetas_a_buscar[0]}")

# 1. Alimentamos a la bestia (imagen + texto)
inputs = processor(text=etiquetas_a_buscar, images=imagen_original, return_tensors="pt").to(device)

with torch.no_grad():
    outputs = model(**inputs)

# 2. Obtenemos las cajas de resultados adaptadas al tamaÃ±o real de tu foto
target_sizes = torch.tensor([imagen_original.size[::-1]])
# Umbral bajo (0.1) para que sea un poco optimista
results = processor.post_process_grounded_object_detection(
    outputs=outputs, 
    target_sizes=target_sizes, 
    text_labels=etiquetas_a_buscar, 
    threshold=0.1
)[0] # Cogemos el resultado de la primera (y Ãºnica) imagen

# Pintar cajas en la foto original para ver cÃ³mo piensa
imagen_anotada = imagen_original.copy()
draw = ImageDraw.Draw(imagen_anotada)

recortes = []
titulos = []

# 3. Analizar lo que ha encontrado
for caja, score, label_idx in zip(results["boxes"], results["scores"], results["labels"]):
    # Extraer coordenadas
    x1, y1, x2, y2 = map(int, caja.tolist())
    
    # Â¿QuÃ© etiqueta corresponde a este Ã­ndice?
    nombre_prenda = etiquetas_a_buscar[0][label_idx.item()]
    confianza = score.item()
    
    # Dibujamos rectÃ¡ngulo rojo en la original
    draw.rectangle([x1, y1, x2, y2], outline="red", width=3)
    draw.text((x1, y1-10), f"{nombre_prenda} ({confianza:.2f})", fill="red")
    
    print(f"âœ… Â¡Encontrado! {nombre_prenda.upper()} con {confianza*100:.1f}% de seguridad.")
    
    # Recortamos la prenda y la guardamos para enseÃ±arla luego
    recorte = imagen_original.crop((x1, y1, x2, y2))
    recortes.append(recorte)
    titulos.append(f"{nombre_prenda}\nScore: {confianza:.2f}")

# 4. Mostrar el show visual
if len(recortes) > 0:
    print("Encontrado elementos")
else:
    print("ğŸ¤·â€â™‚ï¸ OwlViT no ha logrado ver ninguna de esas prendas en la foto con >10% seguridad.")
