{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b21487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Arrancando 'El Etiquetador Inteligente' en: cuda\n",
      "üìö Cruzando los datos de Inditex...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dea63453c04b95960bdaa9c1d13ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/412 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mOwlViTForObjectDetection LOAD REPORT\u001b[0m from: google/owlvit-base-patch32\n",
      "Key                                         | Status     |  | \n",
      "--------------------------------------------+------------+--+-\n",
      "owlvit.vision_model.embeddings.position_ids | UNEXPECTED |  | \n",
      "owlvit.text_model.embeddings.position_ids   | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî™ Extrayendo e identificando ropa de 1876 modelos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1876/1876 [03:16<00:00,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ ¬°PASO 1 COMPLETADO! Has generado 316 im√°genes etiquetadas.\n",
      "Revisa la carpeta: /home/aleixbertranandreu/Documents/HackUDC_2026/data/dataset_entrenar_IA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import OwlViTProcessor, OwlViTForObjectDetection\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. CONFIGURACI√ìN A PRUEBA DE BALAS ---\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üöÄ Arrancando 'El Etiquetador Inteligente' en: {device}\")\n",
    "\n",
    "# Obligamos a Python a usar la ruta absoluta exacta que se ve en tu error\n",
    "BASE_DIR = os.path.expanduser(\"~/Documents/HackUDC_2026\")\n",
    "\n",
    "# üî• RUTAS CORREGIDAS SEG√öN TUS CAPTURAS üî•\n",
    "RUTA_MATCH_TRAIN = os.path.join(BASE_DIR, \"data\", \"raw\", \"bundles_product_match_train.csv\")\n",
    "RUTA_PRODUCTOS = os.path.join(BASE_DIR, \"data\", \"raw\", \"product_dataset.csv\") # <-- ¬°Corregido!\n",
    "CARPETA_BUNDLES = os.path.join(BASE_DIR, \"data\", \"images\", \"bundles\")\n",
    "CARPETA_SALIDA = os.path.join(BASE_DIR, \"data\", \"dataset_entrenar_IA\")\n",
    "\n",
    "# Creamos la carpeta de salida si no existe\n",
    "os.makedirs(CARPETA_SALIDA, exist_ok=True)\n",
    "\n",
    "# --- 2. CARGAR EL \"CHULETERO\" DE INDITEX ---\n",
    "print(\"üìö Cruzando los datos de Inditex...\")\n",
    "df_match = pd.read_csv(RUTA_MATCH_TRAIN)\n",
    "df_products = pd.read_csv(RUTA_PRODUCTOS)\n",
    "\n",
    "# Unimos los dos excels\n",
    "df_info = pd.merge(df_match, df_products, on=\"product_asset_id\")\n",
    "\n",
    "# Mapeo de categor√≠as para que OWL-ViT lo entienda\n",
    "MAPEO_CATEGORIAS = {\n",
    "    'T-SHIRT': 'upper clothing', 'SHIRT': 'upper clothing', 'SWEATER': 'upper clothing',\n",
    "    'JACKET': 'upper clothing', 'COAT': 'upper clothing', 'BLOUSE': 'upper clothing',\n",
    "    'TOP': 'upper clothing', 'TROUSERS': 'lower clothing', 'JEANS': 'lower clothing',\n",
    "    'SHORTS': 'lower clothing', 'SKIRT': 'lower clothing', 'DRESS': 'dress',\n",
    "    'JUMPSUIT': 'dress'\n",
    "}\n",
    "df_info['owl_label'] = df_info['product_description'].map(MAPEO_CATEGORIAS)\n",
    "\n",
    "# --- 3. CARGAMOS LA IA VISUAL ---\n",
    "processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")\n",
    "model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\").to(device)\n",
    "etiquetas_busqueda = [[\"upper clothing\", \"lower clothing\", \"dress\"]]\n",
    "\n",
    "bundles_a_procesar = df_info['bundle_asset_id'].unique()[:3000]\n",
    "\n",
    "print(f\"üî™ Extrayendo e identificando ropa de {len(bundles_a_procesar)} modelos...\")\n",
    "\n",
    "# --- 4. LA MAGIA: CORTAR Y BAUTIZAR ---\n",
    "aciertos_guardados = 0\n",
    "\n",
    "for bundle_id in tqdm(bundles_a_procesar):\n",
    "    ruta_foto = os.path.join(CARPETA_BUNDLES, f\"{bundle_id}.jpg\")\n",
    "    \n",
    "    if not os.path.exists(ruta_foto):\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # Pasamos la foto por OWL-ViT\n",
    "        imagen = Image.open(ruta_foto).convert(\"RGB\")\n",
    "        inputs = processor(text=etiquetas_busqueda, images=imagen, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        target_sizes = torch.tensor([imagen.size[::-1]])\n",
    "        results = processor.post_process_grounded_object_detection(\n",
    "            outputs=outputs, target_sizes=target_sizes, text_labels=etiquetas_busqueda, threshold=0.1\n",
    "        )[0]\n",
    "        \n",
    "        ropa_real_modelo = df_info[df_info['bundle_asset_id'] == bundle_id]\n",
    "        \n",
    "        for caja, score, label_idx in zip(results[\"boxes\"], results[\"scores\"], results[\"labels\"]):\n",
    "            if score.item() > 0.1:\n",
    "                lo_que_ve_la_ia = etiquetas_busqueda[0][label_idx.item()]\n",
    "                match = ropa_real_modelo[ropa_real_modelo['owl_label'] == lo_que_ve_la_ia]\n",
    "                \n",
    "                if not match.empty:\n",
    "                    id_producto_real = match.iloc[0]['product_asset_id']\n",
    "                    \n",
    "                    x1, y1, x2, y2 = map(int, caja.tolist())\n",
    "                    recorte = imagen.crop((x1, y1, x2, y2))\n",
    "                    \n",
    "                    nombre_archivo = f\"{id_producto_real}_from_{bundle_id}.jpg\"\n",
    "                    ruta_salida = os.path.join(CARPETA_SALIDA, nombre_archivo)\n",
    "                    recorte.save(ruta_salida)\n",
    "                    aciertos_guardados += 1\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {bundle_id}: {e}\")\n",
    "\n",
    "print(f\"\\nüèÜ ¬°PASO 1 COMPLETADO! Has generado {aciertos_guardados} im√°genes etiquetadas.\")\n",
    "print(f\"Revisa la carpeta: {CARPETA_SALIDA}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
