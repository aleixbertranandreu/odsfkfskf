{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0fa8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üöÄ Creando el cat√°logo definitivo en: {DEVICE}\")\n",
    "\n",
    "# 1. CARGAMOS EXACTAMENTE EL MISMO MODELO QUE USAMOS PARA INFERENCIA\n",
    "model_id = \"openai/clip-vit-base-patch32\"\n",
    "processor = CLIPProcessor.from_pretrained(model_id)\n",
    "model = CLIPModel.from_pretrained(model_id).to(DEVICE)\n",
    "\n",
    "# 2. RUTAS\n",
    "RUTA_FOTOS_PRODUCTOS = \"../data/images/products/\" # ‚ö†Ô∏è Aseg√∫rate de que esta es la ruta a las fotos del cat√°logo\n",
    "RUTA_CSV_PRODUCTOS = \"../data/raw/product_train.csv\" # ‚ö†Ô∏è El CSV que tiene la info de productos\n",
    "RUTA_NUEVO_PKL = \"../data/embeddings/catalog_embeddings_v2_seguro.pkl\"\n",
    "\n",
    "df_productos = pd.read_csv(RUTA_CSV_PRODUCTOS)\n",
    "catalogo_db = {}\n",
    "\n",
    "print(f\"‚öôÔ∏è Procesando {len(df_productos)} productos...\")\n",
    "\n",
    "# 3. BUCLE DE EXTRACCI√ìN\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for _, fila in tqdm(df_productos.iterrows(), total=len(df_productos)):\n",
    "        id_producto = fila['product_asset_id']\n",
    "        ruta_foto = os.path.join(RUTA_FOTOS_PRODUCTOS, f\"{id_producto}.jpg\")\n",
    "        \n",
    "        if os.path.exists(ruta_foto):\n",
    "            try:\n",
    "                # Abrir imagen\n",
    "                imagen = Image.open(ruta_foto).convert(\"RGB\")\n",
    "                \n",
    "                # Pasar por CLIP\n",
    "                inputs = processor(images=imagen, return_tensors=\"pt\").to(DEVICE)\n",
    "                vision_outputs = model.vision_model(pixel_values=inputs['pixel_values'])\n",
    "                vector = model.visual_projection(vision_outputs.pooler_output)\n",
    "                \n",
    "                # Normalizar MUY IMPORTANTE\n",
    "                vector = vector / vector.norm(dim=-1, keepdim=True)\n",
    "                \n",
    "                # Guardar en diccionario (quitando la dimensi√≥n extra y pas√°ndolo a CPU)\n",
    "                catalogo_db[id_producto] = vector.cpu().squeeze().numpy()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error con {id_producto}: {e}\")\n",
    "\n",
    "# 4. GUARDAR EL NUEVO PKL\n",
    "os.makedirs(os.path.dirname(RUTA_NUEVO_PKL), exist_ok=True)\n",
    "with open(RUTA_NUEVO_PKL, \"wb\") as f:\n",
    "    pickle.dump(catalogo_db, f)\n",
    "\n",
    "print(f\"\\n‚úÖ ¬°Cat√°logo V2 generado con √©xito! Guardado en: {RUTA_NUEVO_PKL}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
