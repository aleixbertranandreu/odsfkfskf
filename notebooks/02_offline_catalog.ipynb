{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd2888c7-cec3-430f-9739-b2c7234aeec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando Pipeline en dispositivo: cuda\n",
      "‚è≥ Cargando OwlViT (Segmentaci√≥n Zero-Shot)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "The image processor of type `OwlViTImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6d816c191444208d7700d1c93cf4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/412 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mOwlViTForObjectDetection LOAD REPORT\u001b[0m from: google/owlvit-base-patch32\n",
      "Key                                         | Status     |  | \n",
      "--------------------------------------------+------------+--+-\n",
      "owlvit.text_model.embeddings.position_ids   | UNEXPECTED |  | \n",
      "owlvit.vision_model.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Cargando CLIP (Extracci√≥n de Features)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `CLIPImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102a84e4c7f54043b6160f88e049dc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mCLIPModel LOAD REPORT\u001b[0m from: openai/clip-vit-base-patch32\n",
      "Key                                  | Status     |  | \n",
      "-------------------------------------+------------+--+-\n",
      "vision_model.embeddings.position_ids | UNEXPECTED |  | \n",
      "text_model.embeddings.position_ids   | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Cargando base de datos vectorial del cat√°logo...\n",
      "‚úÖ Cat√°logo listo: 27687 prendas cargadas. Forma: (27687, 512)\n",
      "üóÇÔ∏è Cargando el Filtro M√°gico de Categor√≠as...\n",
      "üöÄ Iniciando an√°lisis de 2331 bundles con Filtro de Categor√≠as...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando Submission: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [09:06<00:00,  4.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üèÜ ¬°PROCESO TERMINADO! Se ha generado '/home/aleixbertranandreu/Documents/HackUDC_2026/submission_owlvit_filtrado.csv'.\n",
      "==================================================\n",
      "üîç INICIANDO AUDITOR√çA LOCAL DEL MODELO M√ÅGICO...\n",
      "\n",
      "üì∏ Bundle: B_dc4cb6c331e3\n",
      "   ‚úÖ Respuestas correctas (Real): ['I_881901188071', 'I_d052c23db223', 'I_8db63e8e2216', 'I_a02581fea174']\n",
      "   ü§ñ Tu Top 15 ha dicho (Pred): ['I_e628709336c6', 'I_80395cf97ede', 'I_117a41be9d99', 'I_a9572d712c7e', 'I_c6b9413ccd39']... (mostrando 5)\n",
      "   üéØ Aciertos en esta foto: 0 / 4\n",
      "\n",
      "üì∏ Bundle: B_0115d9356e71\n",
      "   ‚úÖ Respuestas correctas (Real): ['I_f052906c12b9', 'I_236665b45fe5', 'I_b3611ad5cf9a']\n",
      "   ü§ñ Tu Top 15 ha dicho (Pred): ['I_c903207825c3', 'I_2b11d7a55b71', 'I_0aa60bff1f68', 'I_4edcb3bf5499', 'I_d79ac5533f76']... (mostrando 5)\n",
      "   üéØ Aciertos en esta foto: 0 / 3\n",
      "\n",
      "üì∏ Bundle: B_356f9aad7c3e\n",
      "   ‚úÖ Respuestas correctas (Real): ['I_4e2056ae9d96', 'I_9897c7d5134a']\n",
      "   ü§ñ Tu Top 15 ha dicho (Pred): ['I_e8320687caf8', 'I_7726f5168dfe', 'I_7426e585acbf', 'I_c80628fc5320', 'I_a75e288ccd82']... (mostrando 5)\n",
      "   üéØ Aciertos en esta foto: 0 / 2\n",
      "\n",
      "üì∏ Bundle: B_a5edb4861ebe\n",
      "   ‚úÖ Respuestas correctas (Real): ['I_d3e8b8b3a6f1', 'I_9d6786a85c68', 'I_ef249de4d682', 'I_19f61d906cd1', 'I_5f3505efd552']\n",
      "   ü§ñ Tu Top 15 ha dicho (Pred): ['I_60dbfe05f5e2', 'I_3e2de58cbaef', 'I_deb4d80b7f00', 'I_96c027e3f6c0', 'I_dece03f0085e']... (mostrando 5)\n",
      "   üéØ Aciertos en esta foto: 0 / 5\n",
      "\n",
      "üì∏ Bundle: B_07bdfaabcc9f\n",
      "   ‚úÖ Respuestas correctas (Real): ['I_a02581fea174', 'I_754def635a8e', 'I_a20f7e68a47e', 'I_412f761f5985', 'I_5d8a1c178078', 'I_05416b56c14d']\n",
      "   ü§ñ Tu Top 15 ha dicho (Pred): ['I_3b8e42a54deb', 'I_82df67faa1ac', 'I_d592ae9c0aae', 'I_7ed733de19f7', 'I_05e5c49e6349']... (mostrando 5)\n",
      "   üéØ Aciertos en esta foto: 0 / 6\n",
      "\n",
      "==================================================\n",
      "üìä RESULTADO DE LA AUDITOR√çA: 0 aciertos de 20 prendas posibles.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- IMPORTAMOS TU SUPER FUNCI√ìN DEL SCRIPT ---\n",
    "import sys\n",
    "# A√±adimos la carpeta ra√≠z al path para poder importar desde src/\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "from src.smart_inference import analizar_bundle_optimizado\n",
    "\n",
    "# 1. Cargamos las respuestas correctas de Inditex\n",
    "# ‚ö†Ô∏è La ruta oficial del set de entrenamiento que tienes en data/raw\n",
    "ruta_train = \"../data/raw/bundles_product_match_train.csv\"\n",
    "df_train = pd.read_csv(ruta_train)\n",
    "\n",
    "# Cogemos solo 5 bundles √∫nicos para hacer la prueba r√°pida\n",
    "bundles_prueba = df_train['bundle_asset_id'].unique()[:5]\n",
    "\n",
    "aciertos_totales = 0\n",
    "prendas_totales_a_adivinar = 0\n",
    "\n",
    "print(\"üîç INICIANDO AUDITOR√çA LOCAL DEL MODELO M√ÅGICO...\")\n",
    "\n",
    "for bundle_id in bundles_prueba:\n",
    "    # ¬øQu√© ropa lleva de verdad esta modelo seg√∫n Inditex?\n",
    "    prendas_correctas = df_train[df_train['bundle_asset_id'] == bundle_id]['product_asset_id'].tolist()\n",
    "    prendas_totales_a_adivinar += len(prendas_correctas)\n",
    "    \n",
    "    # Pasamos la foto por tu modelo\n",
    "    # ‚ö†Ô∏è En el notebook estamos en /notebooks, as√≠ que subimos un nivel con ../\n",
    "    ruta_foto = f\"../data/images/bundles/{bundle_id}.jpg\"\n",
    "    \n",
    "    if not os.path.exists(ruta_foto):\n",
    "        print(f\"‚ö†Ô∏è No encuentro la foto {ruta_foto}, saltando...\")\n",
    "        continue\n",
    "        \n",
    "    predicciones_top_15 = analizar_bundle_optimizado(ruta_foto)\n",
    "    \n",
    "    # Comprobamos cu√°ntas hemos acertado\n",
    "    aciertos = [p for p in prendas_correctas if p in predicciones_top_15]\n",
    "    aciertos_totales += len(aciertos)\n",
    "    \n",
    "    print(f\"\\nüì∏ Bundle: {bundle_id}\")\n",
    "    print(f\"   ‚úÖ Respuestas correctas (Real): {prendas_correctas}\")\n",
    "    print(f\"   ü§ñ Tu Top 15 ha dicho (Pred): {predicciones_top_15[:5]}... (mostrando 5)\")\n",
    "    print(f\"   üéØ Aciertos en esta foto: {len(aciertos)} / {len(prendas_correctas)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"üìä RESULTADO DE LA AUDITOR√çA: {aciertos_totales} aciertos de {prendas_totales_a_adivinar} prendas posibles.\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
